defaults:
  - _self_
  - augmentations: asymmetric.yaml
  - wandb: private.yaml
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

# disable hydra outputs
hydra:
  output_subdir: null
  run:
    dir: .

name: "mocov3-ego4d-tmini-1"
method: "mocov3"
backbone:
  name: "resnet50"
method_kwargs:
  proj_hidden_dim: 4096
  proj_output_dim: 256
  pred_hidden_dim: 4096
  temperature: 0.1
  # theses parameters need to be added (and added to the mocov3 method):
  #  layers: 2    (3 for projector?)
  #  layers_pred: 2
momentum:
  base_tau: 0.996
  final_tau: 0.996
data:
  dataset: ego4d
  train_path: "/home/data/elias/Ego4dDivSubset"
  val_path: None
  format: "h5"
  num_workers: 4
  dataset_kwargs:
    time_window: 15
optimizer:
  name: "lars"
  batch_size: 128
  lr: 0.2
  classifier_lr: 3e-3
  weight_decay: 1e-6
  no_labels: True
scheduler:
  name: "warmup_cosine"
  warmup_epochs: 0.01
checkpoint:
  enabled: True
  dir: "trained_models"
  frequency: 1
  keep_prev: True
  every_n_iter: 5000
auto_resume:
  enabled: True
knn_clb:
  enabled: True
  dataset: cifar10
  train_path:  "/home/elias/solo-learn/datasets"
  val_path:  "/home/elias/solo-learn/datasets"
  num_workers: 4
  batch_size: 16
  k: [ 10, 20, 50, 100 ]
  perform_on_validation: True
  verbose: True

# doesn't work:
# dataset: imagenet
# train_path:  "/home/data/ImageNet/ILSVRC/Data/CLS-LOC/train"
# val_path:  "/home/data/ImageNet/ILSVRC/Data/CLS-LOC/val"


# overwrite PL stuff
max_epochs: 3
devices: 2
sync_batchnorm: True
accelerator: "gpu"
strategy: ddp
precision: 16-mixed
no_validation: True # important since we have no validation split
limit_val_batches: 0
num_sanity_val_steps: 0
log_every_n_steps: 10 # increase for larger runs
limit_train_batches: 0.01 # percentile or total batches (1.0 for full run)